{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas() # activate the tqdm for pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import copy\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "# to use data structures\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# OpenAI API\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load the API keys from .env\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY loaded\n"
     ]
    }
   ],
   "source": [
    "# now we want to load the API keys from the .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "#check that we have the needed keys\n",
    "for api_key in [\"OPENAI_API_KEY\"]:\n",
    "    if os.getenv(api_key) != None:\n",
    "        print(api_key, \"loaded\")\n",
    "    else:\n",
    "        print(api_key,\"missing\")\n",
    "        print(\"Please create a .env file with the corresponding API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI's API calls\n",
    "\n",
    "We first need to initialize the OpenAI client.\n",
    "\n",
    "> If the code bellow doesn't work, make sure that the `OPEN_AI_KEY` is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the cheapest model `gpt-4o-mini` for all the following codes\n",
    "\n",
    "The messages is the main input of the API. Think of it as the chatbox. `system` messages you can think of as the general instructions, while the `prompt` is the input for those instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = [\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"Write me a poam about the topic of the following text. It should be a short poem, no more than 4 lines. The poem should be in the style of a haiku. The text is: \"},\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \"economics graduate student\"\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # specify the model                                           \n",
    "        messages=msg\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BHYVDeLQPvTfCZMZnOJdZQjeSMV9j', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In data's embrace,  \\nFall leaves whisper wisdom's path,  \\nFuture waits to bloom.  \", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1743523903, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_b376dfbbd5', usage=CompletionUsage(completion_tokens=21, prompt_tokens=59, total_tokens=80, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `completion` will now return with a bunch of data inside (for more detaisl please visit [OpenAI's documentation](https://platform.openai.com/docs/concepts)). \n",
    "\n",
    "To get to the text output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In data's embrace,  \n",
      "Fall leaves whisper wisdom's path,  \n",
      "Future waits to bloom.  \n"
     ]
    }
   ],
   "source": [
    "poem = completion.choices[0].message.content\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get back a `pydantic` type from the [structured outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#page-top). For this we have to define some structure for our outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poem(BaseModel):\n",
    "    title: str\n",
    "    poem: str\n",
    "    sad: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will change the `msg` so that it also tells me if the poem is sad or not. For this, I added a line `sad` and it can take the values True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = [\n",
    "    {\n",
    "        \"role\": \"system\", \"content\": \"Write me a poam about the topic of the following text. It should be a short poem, no more than 4 lines. The poem should be in the style of a haiku. Please also tell me if you think the poem is sad or not and create a title for the poem. The text is: \"},\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \"economics graduate student\"\n",
    "        }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai_client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=msg,\n",
    "        max_completion_tokens = 1024*6,   # this sets the max of tokens it can return \n",
    "                                          # remember that API calls take money from tokens, so more token more expensive\n",
    "        response_format=Poem,           # this is the response format we want to get defined before\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Poem(title='Chasing Numbers', poem='Dreams of figures rise,  \\nClimbing through the graphs of life,  \\nHope for change persists,  \\nKnowledge as my guide.', sad=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the strutured object\n",
    "out = completion.choices[0].message.parsed\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Chasing Numbers',\n",
       " 'poem': 'Dreams of figures rise,  \\nClimbing through the graphs of life,  \\nHope for change persists,  \\nKnowledge as my guide.',\n",
       " 'sad': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can turn the obejct into a dict / json\n",
    "out.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"title\":\"Chasing Numbers\",\"poem\":\"Dreams of figures rise,  \\\\nClimbing through the graphs of life,  \\\\nHope for change persists,  \\\\nKnowledge as my guide.\",\"sad\":false}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can turn the obejct into a dict / json\n",
    "out.model_dump_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using data\n",
    "\n",
    "I have a dataset of the responses of psycologists to comments from patients from [Kaggle](https://www.kaggle.com/datasets/thedevastator/nlp-mental-health-conversations?resource=download)\n",
    "\n",
    "I want to use the generative AI to clasify the comments of the psycologist as appropiate or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>My boyfriend is in Ireland for 11 days, and I ...</td>\n",
       "      <td>It sounds like you and your boyfriend are very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>I have so many issues to address. I have a his...</td>\n",
       "      <td>I think this is a very common question that pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>After 40 years of being straight, how could I ...</td>\n",
       "      <td>Sexuality is normally formed during adolescenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>I feel like I took our relationship for grante...</td>\n",
       "      <td>A key factor in a relationship is trust.I'd st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>I crave attention, companionship, and sex. She...</td>\n",
       "      <td>Hi Hampton,Although I'd bet your wife also wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>He said he would try and he never did. It's be...</td>\n",
       "      <td>If your husband is changing his mind about whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>I always feel the need to impress people, whet...</td>\n",
       "      <td>It is normal to seek other’s attention and not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>We're in an eight year relationship. My boyfri...</td>\n",
       "      <td>First, let me extend my compassion to both of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>I've gone to a couple therapy sessions so far ...</td>\n",
       "      <td>Yes, it is completely normal to feel anxious a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>He is an adolescent. He has peed his pant mult...</td>\n",
       "      <td>Sounds as though your son is \"pissed off\" abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>I'm being verbally abused on a daily basis by ...</td>\n",
       "      <td>I am so sorry this is happening to you.  One t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>I am always arguing with my father. He gets st...</td>\n",
       "      <td>Thanks for the question. Regardless of whether...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>As a child, my parents injured my brother, so ...</td>\n",
       "      <td>Sorry to hear of having witnessed violence wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>I've pretty much been on my own since day one,...</td>\n",
       "      <td>One way to concentrate is that if your mind st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>Is it normal for people to cry during therapy,...</td>\n",
       "      <td>Yes, it's totally normal! Crying is a part of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>I’m facing severe depression and anxiety and I...</td>\n",
       "      <td>Working with a great therapist who can help yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>It happens especially at me and my sister, and...</td>\n",
       "      <td>You are very wise for a young person. You have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>I am currently suffering from erectile dysfunc...</td>\n",
       "      <td>Hi, First and foremost, I want to acknowledge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>I am not sure if I am depressed. I don't know ...</td>\n",
       "      <td>I am so sorry you are struggling!  I do think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>I've been bulimic for about 6 years now. I'm i...</td>\n",
       "      <td>Eating disorders usually result from a sense o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  \\\n",
       "3296  My boyfriend is in Ireland for 11 days, and I ...   \n",
       "2011  I have so many issues to address. I have a his...   \n",
       "1683  After 40 years of being straight, how could I ...   \n",
       "1560  I feel like I took our relationship for grante...   \n",
       "1267  I crave attention, companionship, and sex. She...   \n",
       "2895  He said he would try and he never did. It's be...   \n",
       "2697  I always feel the need to impress people, whet...   \n",
       "1042  We're in an eight year relationship. My boyfri...   \n",
       "3312  I've gone to a couple therapy sessions so far ...   \n",
       "2788  He is an adolescent. He has peed his pant mult...   \n",
       "606   I'm being verbally abused on a daily basis by ...   \n",
       "1443  I am always arguing with my father. He gets st...   \n",
       "2576  As a child, my parents injured my brother, so ...   \n",
       "1078  I've pretty much been on my own since day one,...   \n",
       "1948  Is it normal for people to cry during therapy,...   \n",
       "73    I’m facing severe depression and anxiety and I...   \n",
       "2687  It happens especially at me and my sister, and...   \n",
       "1606  I am currently suffering from erectile dysfunc...   \n",
       "266   I am not sure if I am depressed. I don't know ...   \n",
       "1501  I've been bulimic for about 6 years now. I'm i...   \n",
       "\n",
       "                                               Response  \n",
       "3296  It sounds like you and your boyfriend are very...  \n",
       "2011  I think this is a very common question that pe...  \n",
       "1683  Sexuality is normally formed during adolescenc...  \n",
       "1560  A key factor in a relationship is trust.I'd st...  \n",
       "1267  Hi Hampton,Although I'd bet your wife also wan...  \n",
       "2895  If your husband is changing his mind about whe...  \n",
       "2697  It is normal to seek other’s attention and not...  \n",
       "1042  First, let me extend my compassion to both of ...  \n",
       "3312  Yes, it is completely normal to feel anxious a...  \n",
       "2788  Sounds as though your son is \"pissed off\" abou...  \n",
       "606   I am so sorry this is happening to you.  One t...  \n",
       "1443  Thanks for the question. Regardless of whether...  \n",
       "2576  Sorry to hear of having witnessed violence wit...  \n",
       "1078  One way to concentrate is that if your mind st...  \n",
       "1948  Yes, it's totally normal! Crying is a part of ...  \n",
       "73    Working with a great therapist who can help yo...  \n",
       "2687  You are very wise for a young person. You have...  \n",
       "1606  Hi, First and foremost, I want to acknowledge ...  \n",
       "266   I am so sorry you are struggling!  I do think ...  \n",
       "1501  Eating disorders usually result from a sense o...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mental_health = pd.read_csv(\"data/mental_health.csv\")\n",
    "mental_health.rename(columns={\"Context\": \"Comment\"}, inplace=True)\n",
    "mental_health.dropna(inplace=True)\n",
    "\n",
    "# take a sample of 20 responses\n",
    "mental_health = mental_health.sample(20, random_state=1337)\n",
    "mental_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_msg(row):\n",
    "    msg = [\n",
    "        {\n",
    "            \"role\": \"system\", \"content\": \"Read the folling comversation between two people. The first person a patient and the second one is a mental health professional. Please rate from 1-5 how appropiate you think is the response of the mental health professional. 1 is not appropiate at all and 5 is very appropiate. Please provide a confidence level of your rating from 50 (uncertain) to 100 (certain) and show your logical thinking as 'cot' \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": \"Patient: \" + row[\"Comment\"] + \"\\n Mental Health Professional: \" + row[\"Response\"] + \"\\n\"\n",
    "        }\n",
    "    ]\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39b360a8a9c40c1ab84d6ffe91a1a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mental_health['msg'] = mental_health.progress_apply(create_msg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    rating: int\n",
    "    confidence: int\n",
    "    cot: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_API_call(msg):\n",
    "    completion = openai_client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=msg,\n",
    "        max_completion_tokens = 1024*6,                # Most likely will need this high for the cot\n",
    "        response_format=Response,           # this is the response format we want to get defined before\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378e1ada6e1b4fa1ae6196f941246b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = mental_health['msg'].progress_apply(structured_API_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = [obj.rating for obj in answers]\n",
    "confidence = [obj.confidence for obj in answers]\n",
    "cot = [obj.cot for obj in answers]\n",
    "\n",
    "mental_health['rating'] = ratings\n",
    "mental_health['confidence'] = confidence\n",
    "mental_health['cot'] = cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='rating'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mental_health['rating'].value_counts().sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment:  I've pretty much been on my own since day one, I'm a middle child of five, and I can't seem to put my trust in anyone. It took me four years to finally open up a little to my best friend. Every time I realize that I have feelings for someone, I freak out and never talk to them again. I really want some help.\n",
      "Response:  One way to concentrate is that if your mind starts to wonder then remind yourself to bring your attention back.Start with short time spans of expecting yourself to concentrate.  You'll more likely succeed with concentrating with small time spans than longer ones.Once you start seeing your success, this will motivate you to try increasing the length to expect yourself to concentrate.The task of self-reminding is the same, whether for long or short time periods.Also, before starting this exercise ask your medical doctor if the problem can be related to a physical health problem.If there is, then have the possibility ruled out that your difficulty concentrating comes from the mental ability to concentrate, and not some medical reason preventing this.Before someone can engage their psychological will there must be a clean medical body and mind with which to work.\n",
      "Rating:  1\n",
      "Confidence:  80\n",
      "Cot:  [\"The patient is expressing deep emotional struggles related to trust and relationships. The response from the mental health professional does not address these specific concerns and instead veers off into discussing concentration techniques, which are not relevant to the patient's issues. A more appropriate response would have involved exploring the patient's feelings, fears about trust, and possible strategies for building relationships. Therefore, I rated the response as 1 (not appropriate at all). My confidence in this rating is moderate at 80 because while the conversational focus was misplaced, the professional's intent for helping through techniques could be seen as well-meaning.\"]\n",
      "\n",
      "\n",
      "Comment:  I've been bulimic for about 6 years now. I'm in my early 20s. I am about to start back to school to become an RN, and I really need to get better once and for all.    I lose control of myself and become angry and anxious and just eat and purge. Over and over. Can someone please point me in the right direction for help?\n",
      "Response:  Eating disorders usually result from a sense of insecurity about who the person is, whether they are good enough compared with anyone else, and whether the way they person lives is effective.If you have a style you're already happy with to reflect on these sorts of topics, keep following your own logic with the aim to free yourself, which usually takes place gradually, from these sort of self-doubts.The other approach would be to find an unperson or an online discussion group where you'd be able to offer and receive the support from other people who live with a similar problem.Good luck in your studies!\n",
      "Rating:  2\n",
      "Confidence:  60\n",
      "Cot:  [\"The mental health professional's response does touch on the underlying issues of self-doubt and insecurity which can be related to eating disorders. However, it lacks direct advice or active strategies for seeking treatment for bulimia specifically, which is what the patient is asking for.\", \"The mention of finding a support group is slightly beneficial, but the advice feels vague and generalized rather than targeted to the patient's specific needs and situation at the moment.\", 'Furthermore, the statement ends abruptly without more details or encouragement regarding professional therapy or counseling options, which are crucial steps for someone struggling with bulimia.', 'Overall, while the intent may be supportive, the lack of focused and practical steps limits the appropriateness of the response.']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what where the ones with lower ratings?\n",
    "low_ratings = mental_health[mental_health['rating'] < 3]\n",
    "\n",
    "for row in low_ratings.iterrows():\n",
    "    print(\"Comment: \", row[1]['Comment'])\n",
    "    print(\"Response: \", row[1]['Response'])\n",
    "    print(\"Rating: \", row[1]['rating'])\n",
    "    print(\"Confidence: \", row[1]['confidence'])\n",
    "    print(\"Cot: \", row[1]['cot'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open source with HuggingFace\n",
    "\n",
    "Instead of paying for API calls we can use the computer resources. For this we use the package transformers!\n",
    "\n",
    "In this case we will use a super lightweight model, so we don't overwhelm the computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal Performance Shaders) is available for macOS GPU acceleration\n"
     ]
    }
   ],
   "source": [
    "# check to see that GPU's are active and how many\n",
    "gpu_avail = torch.cuda.is_available()\n",
    "mps_avail = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()\n",
    "\n",
    "if gpu_avail:\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}:\")\n",
    "        print(f\"  Name: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "elif mps_avail:\n",
    "    print(\"MPS (Metal Performance Shaders) is available for macOS GPU acceleration\")\n",
    "else:\n",
    "    print(\"No GPU or MPS detected. Please check you asked for the resources or have a GPU on your computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the SuperPod HPC, you can see almost 80gb of VRAM to use!\n",
    "\n",
    "If you see that GPU or MPS is not detected, the model will be loaded on the CPU and inference will be super slow.\n",
    "\n",
    "For this notebook we will use a lightweight model that will take no more than 4gb of VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the model using [`pipeline`](http://bcm-dgxa100-0005:8888/lab?token=3179442dd49254ece431fe36b5e001dda40c6a5ed48247a8) which simplifies a lot of the model configuration.\n",
    "\n",
    "We will use small version of [Mistral](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503) from this [Huggingface repo](https://huggingface.co/alamios/Mistral-Small-3.1-DRAFT-0.5B). Because of the size, performance will not be great. \n",
    "\n",
    "However, I've been able to run big models like [Deepseek Llama 3.3-70b](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B) at full precision (or quantization) in 2 SuperPod GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jjgecon/Library/CloudStorage/OneDrive-Personal/Work/GitHub Repos/NLP_starter/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.15` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/Users/jjgecon/Library/CloudStorage/OneDrive-Personal/Work/GitHub Repos/NLP_starter/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.15` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=\"alamios/Mistral-Small-3.1-DRAFT-0.5B\", \n",
    "    trust_remote_code=True,\n",
    "    do_sample=True,\n",
    "    max_new_tokens = 1024*3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded we can ask it to create the a econ poem\n",
    "\n",
    "> Note: some models are not trained to use the 'system' message, so we just combine the whole prompt into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user',\n",
       "    'content': 'Write me a poam about the topic of the following text. It should be a short poem, no more than 4 lines. The text is: economics graduate student'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'In the quiet of the night,\\nI read the equations, the calculations,\\nThe equations that guide the flow,\\nThe calculations that make the world.\\n\\nThe equations that describe the sky,\\nThe calculations that make the sun,\\nThe equations that tell the story,\\nThe calculations that make the world.\\n\\nThe equations that describe the sky,\\nThe calculations that make the sun,\\nThe equations that tell the story,\\nThe calculations that make the world.'}]}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = [\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \"Write me a poam about the topic of the following text. It should be a short poem, no more than 4 lines. The text is: economics graduate student\"\n",
    "        }\n",
    "]\n",
    "out = pipe(msg)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the quiet of the night,\n",
      "I read the equations, the calculations,\n",
      "The equations that guide the flow,\n",
      "The calculations that make the world.\n",
      "\n",
      "The equations that describe the sky,\n",
      "The calculations that make the sun,\n",
      "The equations that tell the story,\n",
      "The calculations that make the world.\n",
      "\n",
      "The equations that describe the sky,\n",
      "The calculations that make the sun,\n",
      "The equations that tell the story,\n",
      "The calculations that make the world.\n"
     ]
    }
   ],
   "source": [
    "print(out[0]['generated_text'][1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how does it do with the health dataset\n",
    "\n",
    "> I will also simplify the message a bit so that we can get something usefull from this small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_msg(row):\n",
    "    msg = [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": f\"\"\"Read the folling comversation between two people. The first person a patient and the second one is a mental health professional. Please rate the professional's response on a score 1 if you think it was appropiate and 0 if it was not.\n",
    "            Patient: {row[\"Comment\"]} \n",
    "            Mental Health Professional: {row[\"Response\"]}\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4df957427be4edeaef0d4ee892ebc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mental_health['msg_open_source'] = mental_health.progress_apply(create_msg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_source_genai(msg):\n",
    "    out = pipe(msg)\n",
    "    return out[0]['generated_text'][1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0799be1a0774476c8eae959ab7339d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = mental_health['msg_open_source'].progress_apply(open_source_genai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the conversation, here is a rating:\n",
      "\n",
      "1 (appropiate)\n",
      "\n",
      "The professional's response is clear and concise, addressing the patient's concerns about their mental health issues and the importance of seeking help. They acknowledge the patient's history of sexual abuse, breast cancer survivor, and lifetime insomniac, and mention that counseling is a common and necessary step in addressing these issues. The professional also encourages the patient to seek help from a licensed counselor who has experience in trauma, grief/loss, and provides specific strategies to manage symptoms. The response is well-structured and provides a clear and empathetic approach to the patient's situation.\n"
     ]
    }
   ],
   "source": [
    "print(answers.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the conversation, here are my responses:\n",
      "\n",
      "1. **Patient:** \"I've gone to a couple therapy sessions so far and still everytime I walk in I get nervous and shaky. Is this normal? Should I still be feeling like this?\"\n",
      "   - **Mental Health Professional:** \"Yes, it is completely normal to feel anxious about therapy. Therapy often explores topics and feelings that are uncomfortable. The ultimate goal of therapy is to feel better but the process itself can be uncomfortable. It's important to remember that everyone's experience with therapy is unique, and it's normal to feel a range of emotions during the initial sessions. If you're still feeling anxious, it's okay to acknowledge that and to seek support from friends, family, or a professional if you'd like. Remember, therapy is a collaborative effort, and you don't have to go through it alone.\"\n",
      "\n",
      "2. **Patient:** \"Should I still be feeling like this?\"\n",
      "   - **Mental Health Professional:** \"It's completely normal to feel anxious about therapy. Therapy often explores topics and feelings that are uncomfortable. The ultimate goal of therapy is to feel better but the process itself can be uncomfortable. If you're still feeling anxious, it's okay to acknowledge that and to seek support from friends, family, or a professional if you'd like. Remember, therapy is a collaborative effort, and you don't have to go through it alone.\"\n",
      "\n",
      "Overall, the professional's response is helpful and provides a clear understanding of the normal experience of therapy, emphasizing the importance of seeking support and acknowledging that everyone's journey is unique.\n"
     ]
    }
   ],
   "source": [
    "print(answers.iloc[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the answers are not in a very structured way? How can we improve this?\n",
    "\n",
    "In these types of model we can incorporate how we want them to respond in the prompt and then we make some validations using `pydantic` structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    appropiate: bool\n",
    "    thinking: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_msg(row):\n",
    "\n",
    "    patient_psyc_chat = f\"\"\"\n",
    "    Patient: {row[\"Comment\"]} \n",
    "    Mental Health Professional: {row[\"Response\"]}\n",
    "    \"\"\"\n",
    "\n",
    "    json_out = \"\"\"\n",
    "    Please output the following JSON object first, with no extra text before it and avoid using \" in any strings:\n",
    "    {\n",
    "        \"appropiate\": bool,\n",
    "        \"thinking\": str\n",
    "    }\n",
    "    \"\"\"\n",
    "    msg = [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": \"\"\"Read the folling comversation between two people. The first person a patient and the second one is a mental health professional. Please rate the professional's response if it is appropiate or not. Please also provide your thinking in one sentece.\"\"\" + patient_psyc_chat + json_out\n",
    "        }\n",
    "    ]\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa1a042528843d0b7fea692efdd6ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32670fdfa2d34bec9c9f2f9fa6431581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mental_health['msg_open_source'] = mental_health.progress_apply(create_msg, axis=1)\n",
    "answers = mental_health['msg_open_source'].progress_apply(open_source_genai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "2011    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1683    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1560    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1267    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "2895    Based on the conversation, here is the JSON ob...\n",
       "2697    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1042    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "3312    {\\n        \"appropiate\": true,\\n        \"think...\n",
       "2788    To determine if the professional's response is...\n",
       "606     To provide an appropriate response, I'll follo...\n",
       "1443    Based on the conversation, here is the output ...\n",
       "2576    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1078    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1948    {\\n        \"appropiate\": true,\\n        \"think...\n",
       "73      {\\n        \"appropiate\": true,\\n        \"think...\n",
       "2687    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1606    To determine if the professional's response is...\n",
       "266     {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "1501    {\\n        \"appropiate\": false,\\n        \"thin...\n",
       "Name: msg_open_source, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "        \"appropiate\": false,\n",
      "        \"thinking\": \"It sounds like you and your boyfriend are very close.  Do you typically spend most of your time together?  If so, it may be important to reflect on how you feel when you are apart.  If any separation is difficult, you may need to examine why.  Think about what it is that you miss and what you are anxious, upset or worried about.  If you examine the causes of your distress, you likely will experience some relief.  It is important to learn how to be happy when you are alone, it will only improve the way you feel when you are with your boyfriend.\"\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "print(answers.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the conversation, here is the JSON object:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"appropiate\": false,\n",
      "    \"thinking\": \"I'm not sure if I should respect his decision to leave, especially if he's constantly changing his mind and leaving me crying and worried every night. I'm worried about the impact this will have on our relationship and my mental health. I've been trying to see a therapist who specializes in couples, but I'm not sure if I should trust his judgment. He's constantly changing his mind about whether or not to stay together, and I'm worried about the impact this will have on our relationship and my mental health.\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Reasoning:\n",
      "1. **Patient's Statement**: The patient mentions that their husband has been changing his mind about whether or not to stay in the relationship, which is a significant issue. They also mention that they are worried about the impact this will have on their relationship and mental health.\n",
      "2. **Mental Health Professional's Response**: The professional acknowledges that the patient's husband is changing his mind about staying together, but they also mention that the decision is not solely the patient's fault. The professional suggests that the patient should weigh the options of an important decision (such as whether to stay together) and that having a therapist can help navigate this process.\n",
      "3. **Patient's Response**: The patient expresses uncertainty about whether they should respect their husband's decision to leave, especially if he is constantly changing his mind and leaving them crying and worried every night. They also mention that they are worried about the impact this will have on their relationship and mental health.\n",
      "\n",
      "Given these points, the professional's response is not appropriate because it does not address the patient's concerns about the impact of their husband's decision on their relationship and mental health. The patient's statement about the decision itself is a valid concern, but the professional's response does not address the patient's emotional and psychological needs.\n"
     ]
    }
   ],
   "source": [
    "print(answers.iloc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To validate the responses we will need to extract the json from the output and then validate if it's correct.\n",
    "\n",
    "Therefore there can be 2 problems:\n",
    "1. The model does not provide the JSON structure\n",
    "2. The model provides a JSON but it's not in the format we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_output(answ, pydantic_model):\n",
    "    \"\"\"\n",
    "    Created by Copilot\n",
    "    Validate the output of the model against a Pydantic model.\n",
    "    \"\"\"\n",
    "    # Try to extract JSON from the response\n",
    "    json_match = re.search(r'```json\\s*(.*?)\\s*```', answ, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(1)\n",
    "    else:\n",
    "        # If no JSON code block, try to find a JSON-like structure\n",
    "        json_match = re.search(r'\\{.*\\}', answ, re.DOTALL)\n",
    "        if json_match:\n",
    "            json_str = json_match.group(0)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # Try to parse the JSON\n",
    "    try:\n",
    "        json_obj = json.loads(json_str)\n",
    "        # Validate against the Pydantic model\n",
    "        validated = pydantic_model(**json_obj)\n",
    "        return validated\n",
    "    except (json.JSONDecodeError, ValueError) as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296    appropiate=False thinking='It sounds like you ...\n",
       "2011    appropiate=False thinking='I think this is a v...\n",
       "1683    appropiate=False thinking='I would explore whe...\n",
       "1560    appropiate=False thinking=\"It seems like you'r...\n",
       "1267    appropiate=False thinking=\"I don't know what t...\n",
       "2895    appropiate=False thinking=\"I'm not sure if I s...\n",
       "2697    appropiate=False thinking='Es común que busque...\n",
       "1042    appropiate=False thinking=\"I don't know how to...\n",
       "3312    appropiate=True thinking='It is completely nor...\n",
       "2788    appropiate=False thinking=\"The professional's ...\n",
       "606     appropiate=False thinking=\"I am feeling overwh...\n",
       "1443    appropiate=False thinking='I am always arguing...\n",
       "2576    appropiate=False thinking=\"I don't have the in...\n",
       "1078    appropiate=False thinking=\"I've pretty much be...\n",
       "1948    appropiate=True thinking=\"Yes, it's totally no...\n",
       "73      appropiate=True thinking='Working with a great...\n",
       "2687    appropiate=False thinking=\"It's normal for som...\n",
       "1606    appropiate=True thinking=\"The professional ack...\n",
       "266     appropiate=False thinking=\"I am not sure if I ...\n",
       "1501    appropiate=False thinking=\"It seems like you'r...\n",
       "Name: msg_open_source, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_answers = answers.apply(lambda x: validate_output(x, Response))\n",
    "val_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_answers.iloc[0].appropiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It sounds like you and your boyfriend are very close.  Do you typically spend most of your time together?  If so, it may be important to reflect on how you feel when you are apart.  If any separation is difficult, you may need to examine why.  Think about what it is that you miss and what you are anxious, upset or worried about.  If you examine the causes of your distress, you likely will experience some relief.  It is important to learn how to be happy when you are alone, it will only improve the way you feel when you are with your boyfriend.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_answers.iloc[0].thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have some structured output.\n",
    "\n",
    "> If there is one answer that was not validated and returned None, you can simply ask the model again until you get the correct format.\n",
    "\n",
    "These models are intrincically stochastics (even sometime swhen temperature or do_sample are equal to 0). Although it's good to have outputs that can be replicated for some of these clasification tasks you will need some creativity in the model. I suggest that you save all the responses and ask multiple times the models for answers.\n",
    "\n",
    "In my research I tend to ask the model for the clasification 5 times + some confidence level on the answer. Then I just take those answers that the model agrees on with high confidence.\n",
    "\n",
    "Another option is to use different models and create an ensemble of responses.\n",
    "\n",
    "For more details on how to tailor your prompts please review the document in Prompt Engineering pdf @ `media/Prompt Engineering_google.pdf`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
